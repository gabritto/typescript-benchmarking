# This pipeline handles all TypeScript benchmarking. Supported situations are:
#
# - Pushes to microsoft/TypeScript's main branch. This is triggered indirectly
#   via the ts-main-pipeline resource. In this situation, BuildReason will be
#   ResourceTrigger, and we will upload the results to the blob store.
# - On manual trigger via the API, with a payload like:
#   {
#     "resources": {
#       "repositories": {
#         "TypeScript": { "refName": "refs/heads/main", "version": "<commit hash>" }
#       }
#     },
#     "templateParameters": {
#       "FOR_BASELINE": true
#     }
#   }
#   In this situation, we'll treat this as a backfill run on main and upload
#   the results to the blob store.
# - On manual trigger via the API, with a payload like:
#   {
#     "resources": {
#       "repositories": {
#         "TypeScript": { "refName": "refs/pull/<number>/merge" }
#       }
#     }
#   }
#   In this situation, we'll treat this as a PR run, comparing the pull request
#   against its merge base with main. Its results will be published back to the
#   pull request as a comment. Note that this payload is not one that the UI
#   supports, but it's possible to manually trigger it via the API, in which
#   case the UI will properly render all details about the resources.
#
# TODO: We should also support running on release branches, both for new
# commits and for backfilling.

# General TODOs:
# - The extra info for the benchmarks is empty.
# - On PRs, rerun ts-perf to show the difference for one benchmark.

pr: none
trigger: none

resources:
  repositories:
    - repository: TypeScript
      type: github
      endpoint: Microsoft
      name: microsoft/TypeScript

  # https://stackoverflow.com/a/63276774
  pipelines:
    - pipeline: ts-main-pipeline
      source: 'TypeScript pipeline trigger'
      trigger:
        branches:
          include:
            - main

  # - name: azureSubscription
  #   value: 'TypeScript Internal Services'
  # - name: KeyVaultName
  #   value: 'jststeam-passwords'
  # - name: SecretsFilter
  #   value: 'tslab1-mseng-PAT, tsperf-azure-storage-connection-string'

parameters:
  # TODO: allow custom preset
  - name: TSPERF_PRESET
    displayName: Preset
    values:
      - full
      - faster
    default: full

  - name: FOR_BASELINE
    displayName: Benchmark run is for baseline tracking; uses a designated machine and uploads. Only uploads when TypeScript's ref is "refs/heads/main".
    type: boolean
    default: false

variables:
  Codeql.Enabled: false
  skipComponentGovernanceDetection: true

  # This is just the version of node used to build TypeScript, run ts-perf, etc.
  # The actual benchmarked node version is controlled by ts-perf.
  NODE_VERSION: '16.x'

  REF: $[ resources.repositories['TypeScript'].ref ]
  # TODO: can we use variables['REF'] below?
  PRETTY_REF: $[ replace(replace(replace(resources.repositories['TypeScript'].ref, '/merge', ''), 'refs/pull/', 'pr.'), 'refs/heads/', '') ]
  IS_PR: $[ startsWith(resources.repositories['TypeScript'].ref, 'refs/pull/') ]
  # Only upload if the provided ref is explicitly main, and either we're triggered by a push to main, or the parameter says we should.
  # This means that main pushes will automatically upload, but we can still queue builds off of main with a specific commit in the API.
  # TODO: what about release branches?
  SHOULD_UPLOAD: $[ and(eq(resources.repositories['TypeScript'].ref, 'refs/heads/main'), or(eq(variables['Build.Reason'], 'ResourceTrigger'), ${{ parameters.FOR_BASELINE }})) ]

name: $(PRETTY_REF)-$(Date:yyyyMMdd).$(Rev:r)
# Hide the commit message from the run name; it'll just always say that the
# build came from the benchmarking repo's commit.
appendCommitMessageToRunName: false

jobs:
  - job: Setup
    pool:
      vmImage: ubuntu-latest
    workspace:
      clean: all # Always start with a clean slate.

    steps:
      - checkout: self
        path: typescript-benchmarking
        fetchTags: false
        fetchDepth: 1
        clean: true

      - bash: |
          # TODO: pass in custom preset parameters
          cd $(Pipeline.Workspace)/typescript-benchmarking
          node ./scripts/generateMatrix.mjs ${{ parameters.TSPERF_PRESET }}
        displayName: Generate matrix
        name: generateMatrix

      - checkout: TypeScript
        path: TypeScript
        fetchTags: false
        fetchDepth: 2 # For PRs, we want the merge base to compare against.
        clean: true

      - task: NodeTool@0
        inputs:
          versionSpec: $(NODE_VERSION)
        displayName: 'Install Node $(NODE_VERSION)'

      - bash: |
          mkdir artifacts
          CHECKOUT=$(Pipeline.Workspace)/TypeScript

          build_typescript() {
            NAME=$1
            OUTPUT=$2

            pushd ${CHECKOUT}

            COMMIT=$( git -C ${CHECKOUT} rev-parse HEAD )
            COMMIT_SHORT=$( git -C ${CHECKOUT} rev-parse --short HEAD )
            DATE=$( git -C ${CHECKOUT} log -1 --format=%cI )
            TIMESTAMP_DIR=$( date -d ${DATE} -u +%Y/%m/%d )

            echo "##vso[task.setvariable variable=${NAME}_COMMIT;isOutput=true]${COMMIT}"
            echo "##vso[task.setvariable variable=${NAME}_COMMIT_SHORT;isOutput=true]${COMMIT_SHORT}"
            echo "##vso[task.setvariable variable=${NAME}_DATE;isOutput=true]${DATE}"
            echo "##vso[task.setvariable variable=${NAME}_TIMESTAMP_DIR;isOutput=true]${TIMESTAMP_DIR}"

            npm ci
            npm run clean
            npm run build:compiler
            mv built/local ${OUTPUT}

            popd
          }

          if [[ $(REF) == refs/pull/* ]]; then
            build_typescript PR $(Build.SourcesDirectory)/artifacts/pr
            git -C ${CHECKOUT} switch --detach HEAD^1
          fi
          build_typescript MAIN $(Build.SourcesDirectory)/artifacts/main
        displayName: Build TypeScript
        name: buildTypeScript

      # TODO: should this be a build cache so that it's not preserved?
      - publish: artifacts
        artifact: BuiltTypeScript
        displayName: Publish built TypeScript

  - job: Benchmark
    dependsOn: Setup
    pool:
      name: ts-perf-ddfun
      ${{ if paramters.FOR_BASELINE }}:
        demands: Agent.Name -equals ts-perf1
    workspace:
      clean: all # Always start with a clean slate.

    # https://stackoverflow.com/a/69345058
    strategy:
      matrix: $[ dependencies.Setup.outputs['generateMatrix.MATRIX'] ]

    variables:
      MAIN_COMMIT: $[ dependencies.Setup.outputs['buildTypeScript.MAIN_COMMIT'] ]
      MAIN_COMMIT_SHORT: $[ dependencies.Setup.outputs['buildTypeScript.MAIN_COMMIT_SHORT'] ]
      MAIN_DATE: $[ dependencies.Setup.outputs['buildTypeScript.MAIN_DATE'] ]
      MAIN_TIMESTAMP_DIR: $[ dependencies.Setup.outputs['buildTypeScript.MAIN_TIMESTAMP_DIR'] ]
      PR_COMMIT: $[ dependencies.Setup.outputs['buildTypeScript.PR_COMMIT'] ]
      PR_COMMIT_SHORT: $[ dependencies.Setup.outputs['buildTypeScript.PR_COMMIT_SHORT'] ]
      PR_DATE: $[ dependencies.Setup.outputs['buildTypeScript.PR_DATE'] ]
      PR_TIMESTAMP_DIR: $[ dependencies.Setup.outputs['buildTypeScript.PR_TIMESTAMP_DIR'] ]

    steps:
      # TODO: figure out what perms are missing here
      # https://learn.microsoft.com/en-us/azure/devops/pipelines/release/key-vault-in-own-project?view=azure-devops&tabs=portal#query-and-use-secrets-in-your-pipeline
      # - task: AzureKeyVault@1
      #   inputs:
      #     # This info has been present in CI logs for years; consider these not secret.
      #     azureSubscription: $(azureSubscription)
      #     KeyVaultName: $(KeyVaultName)
      #     SecretsFilter: $(SecretsFilter)

      - bash: git config --global core.longpaths true
        displayName: Enable git long paths

      # These paths are relative to $(Pipeline.Workspace), which is the parent
      # directory of $(Build.SourcesDirectory), the default working directory.
      # TODO: pull these paths out as variables for reuse
      - checkout: self
        path: typescript-benchmarking
        fetchTags: false
        fetchDepth: 1
        clean: true

      - download: current
        artifact: BuiltTypeScript
        displayName: Download built TypeScript

      - task: NodeTool@0
        inputs:
          versionSpec: $(NODE_VERSION)
        displayName: 'Install Node $(NODE_VERSION)'

      # The existence of this AzDo project/repository is not secret.
      # Maybe this should instead use a service connection + checkout? (But, this is temporary anyway.)
      # TODO: also, this sometimes fails to clone; add a retry?
      - bash: git clone --depth=1 https://mseng:${PAT}@mseng.visualstudio.com/Typescript/_git/Typescript internal
        env:
          PAT: $(tslab1-mseng-PAT)
        displayName: Clone internal repo

      - bash: |
          cd internal/scripts/perf
          npx yarn install --frozen-lockfile --prefer-offline
          npx yarn gulp build
        displayName: Build ts-perf

      # This is provided by the agent.
      - bash: sudo pyperf system tune
        displayName: Tune system

      - bash: node internal/scripts/perf/bin/ts-perf host install --host $(TSPERF_HOST)
        displayName: Install hosts

      # TODO: these steps are needlessly repetitive; clean up
      - bash: |
          mkdir -p artifacts

          run_benchmark () {
            node internal/scripts/perf/bin/ts-perf benchmark tsc \
              --cpus ${TSPERF_AGENT_BENCHMARK_CPU} \
              --iterations $(TSPERF_ITERATIONS) \
              --host $(TSPERF_HOST) \
              --scenario $(TSPERF_SCENARIO) \
              "$@"
          }

          if [[ $(REF) == refs/pull/* ]]; then
            echo Running PR benchmark
            run_benchmark \
              --tsc $(Pipeline.Workspace)/BuiltTypeScript/pr/tsc.js \
              --save artifacts/pr_$(TSPERF_HOST)_$(TSPERF_SCENARIO).tsc.benchmark \
              --date $(PR_DATE) \
              --repositoryType git \
              --repositoryUrl ${REPOSITORY_URI} \
              --repositoryBranch $(REF) \
              --repositoryCommit $(PR_COMMIT) \
              --repositoryDate $(PR_DATE)
            echo Running baseline benchmark
          fi
          run_benchmark \
            --tsc $(Pipeline.Workspace)/BuiltTypeScript/main/tsc.js \
            --save artifacts/main_$(TSPERF_HOST)_$(TSPERF_SCENARIO).tsc.benchmark \
            --date $(MAIN_DATE) \
            --repositoryType git \
            --repositoryUrl ${REPOSITORY_URI} \
            --repositoryBranch $(REF) \
            --repositoryCommit $(MAIN_COMMIT) \
            --repositoryDate $(MAIN_DATE)
        displayName: Run tsc benchmark
        condition: and(succeeded(), eq(variables['TSPERF_KIND'], 'tsc'))

      - bash: |
          mkdir -p artifacts

          run_benchmark () {
            node internal/scripts/perf/bin/ts-perf benchmark tsserver \
              --cpus ${TSPERF_AGENT_BENCHMARK_CPU} \
              --iterations $(TSPERF_ITERATIONS) \
              --host $(TSPERF_HOST) \
              --scenario $(TSPERF_SCENARIO) \
              "$@"
          }

          if [[ $(REF) == refs/pull/* ]]; then
            echo Running PR benchmark
            run_benchmark \
              --tsserver $(Pipeline.Workspace)/BuiltTypeScript/pr/tsserver.js \
              --save artifacts/pr_$(TSPERF_HOST)_$(TSPERF_SCENARIO).tsserver.benchmark \
              --date $(PR_DATE) \
              --repositoryType git \
              --repositoryUrl ${REPOSITORY_URI} \
              --repositoryBranch $(REF) \
              --repositoryCommit $(PR_COMMIT) \
              --repositoryDate $(PR_DATE)
            echo Running baseline benchmark
          fi
          run_benchmark \
            --tsserver $(Pipeline.Workspace)/BuiltTypeScript/main/tsserver.js \
            --save artifacts/main_$(TSPERF_HOST)_$(TSPERF_SCENARIO).tsserver.benchmark \
            --date $(MAIN_DATE) \
            --repositoryType git \
            --repositoryUrl ${REPOSITORY_URI} \
            --repositoryBranch $(REF) \
            --repositoryCommit $(MAIN_COMMIT) \
            --repositoryDate $(MAIN_DATE)
        displayName: Run tsserver benchmark
        condition: and(succeeded(), eq(variables['TSPERF_KIND'], 'tsserver'))

      - bash: |
          mkdir -p artifacts

          run_benchmark () {
            node internal/scripts/perf/bin/ts-perf benchmark startup \
              --cpus ${TSPERF_AGENT_BENCHMARK_CPU} \
              --iterations $(TSPERF_ITERATIONS) \
              --host $(TSPERF_HOST) \
              --scenario $(TSPERF_SCENARIO) \
              "$@"
          }

          if [[ $(REF) == refs/pull/* ]]; then
            echo Running PR benchmark
            run_benchmark \
              --builtDir $(Pipeline.Workspace)/BuiltTypeScript/pr \
              --save artifacts/pr_$(TSPERF_HOST)_$(TSPERF_SCENARIO).startup.benchmark \
              --date $(PR_DATE) \
              --repositoryType git \
              --repositoryUrl ${REPOSITORY_URI} \
              --repositoryBranch $(REF) \
              --repositoryCommit $(PR_COMMIT) \
              --repositoryDate $(PR_DATE)
            echo Running baseline benchmark
          fi
          run_benchmark \
            --builtDir $(Pipeline.Workspace)/BuiltTypeScript/main \
            --save artifacts/main_$(TSPERF_HOST)_$(TSPERF_SCENARIO).startup.benchmark \
            --date $(MAIN_DATE) \
            --repositoryType git \
            --repositoryUrl ${REPOSITORY_URI} \
            --repositoryBranch $(REF) \
            --repositoryCommit $(MAIN_COMMIT) \
            --repositoryDate $(MAIN_DATE)
        displayName: Run startup benchmark
        condition: and(succeeded(), eq(variables['TSPERF_KIND'], 'startup'))

      - publish: artifacts
        artifact: Benchmark_$(TSPERF_HOST)_$(TSPERF_SCENARIO)
        displayName: Publish benchmarks

  - job: ProcessResults
    dependsOn:
      - Setup
      - Benchmark
    pool:
      vmImage: ubuntu-latest
    workspace:
      clean: all # Always start with a clean slate.

    variables:
      TSPERF_RUN_TSC: $[ dependencies.Setup.outputs['generateMatrix.TSPERF_RUN_TSC'] ]
      TSPERF_RUN_TSSERVER: $[ dependencies.Setup.outputs['generateMatrix.TSPERF_RUN_TSSERVER'] ]
      TSPERF_RUN_STARTUP: $[ dependencies.Setup.outputs['generateMatrix.TSPERF_RUN_STARTUP'] ]

    steps:
      - download: current
        patterns: '**/*.benchmark'
        displayName: Download benchmarks

      # Azure Pipelines haphazardly drops all artifacts into pipeline workspace with no
      # way to customize where they're placed. To deal with this, we download the benchmarks
      # first and move them somewhere else, before doing any other steps that would download
      # further artifacts.
      - bash: |
          shopt -s globstar # TODO: this wasn't here before but it seemed to have worked
          mkdir artifacts
          mv $(Pipeline.Workspace)/**/*.benchmark artifacts
        displayName: Move artifacts

      # TODO: We only need this because ts-perf requires it even for loading existing benchmarks
      - download: current
        artifact: BuiltTypeScript
        displayName: Download built TypeScript

      - bash: git clone --depth=1 --branch=gabritto/mergeBenchmark https://mseng:${PAT}@mseng.visualstudio.com/Typescript/_git/Typescript internal
        env:
          PAT: $(tslab1-mseng-PAT)
        displayName: Clone internal repo

      - bash: |
          cd internal/scripts/perf
          npx yarn install --frozen-lockfile --prefer-offline
          npx yarn gulp build
        displayName: Build ts-perf

      - bash: mkdir output
        displayName: Create output directory

      # TODO: these steps are needlessly repetitive; clean up
      - bash: |
          if [[ $(REF) == refs/pull/* ]]; then
            node internal/scripts/perf/bin/ts-perf merge --output output/pr.tsc.benchmark artifacts/pr_*.tsc.benchmark
            node internal/scripts/perf/bin/ts-perf merge --output output/main.tsc.benchmark artifacts/main_*.tsc.benchmark

            node internal/scripts/perf/bin/ts-perf benchmark tsc \
              --tsc $(Pipeline.Workspace)/BuiltTypeScript/main/tsc.js \
              --baseline output/main.tsc.benchmark \
              --load output/pr.tsc.benchmark

            echo "<h2>Compiler</h2>" >> comment.html
            node internal/scripts/perf/bin/ts-perf benchmark tsc \
              --tsc $(Pipeline.Workspace)/BuiltTypeScript/main/tsc.js \
              --baseline output/main.tsc.benchmark \
              --load output/pr.tsc.benchmark \
              --baselineName main \
              --benchmarkName pr \
              --format html-fragment \
              --quiet >> comment.html
          else
            node internal/scripts/perf/bin/ts-perf merge --output output/main.tsc.benchmark artifacts/*.tsc.benchmark
            # TODO: publish blob, only on ResourceTrigger or explicit parameter true
            node internal/scripts/perf/bin/ts-perf benchmark tsc \
              --tsc $(Pipeline.Workspace)/BuiltTypeScript/main/tsc.js \
              --load output/main.tsc.benchmark
          fi
        displayName: Merge tsc benchmarks
        condition: and(succeeded(), eq(variables['TSPERF_RUN_TSC'], true))

      - bash: |
          if [[ $(REF) == refs/pull/* ]]; then
            node internal/scripts/perf/bin/ts-perf merge --output output/pr.tsserver.benchmark artifacts/pr_*.tsserver.benchmark
            node internal/scripts/perf/bin/ts-perf merge --output output/main.tsserver.benchmark artifacts/main_*.tsserver.benchmark

            node internal/scripts/perf/bin/ts-perf benchmark tsserver \
              --tsserver $(Pipeline.Workspace)/BuiltTypeScript/main/tsserver.js \
              --baseline output/main.tsserver.benchmark \
              --load output/pr.tsserver.benchmark

            echo "<h2>TSServer</h2>" >> comment.html
            node internal/scripts/perf/bin/ts-perf benchmark tsserver \
              --tsserver $(Pipeline.Workspace)/BuiltTypeScript/main/tsserver.js \
              --baseline output/main.tsserver.benchmark \
              --load output/pr.tsserver.benchmark \
              --baselineName main \
              --benchmarkName pr \
              --format html-fragment \
              --quiet >> comment.html
          else
            node internal/scripts/perf/bin/ts-perf merge --output output/main.tsserver.benchmark artifacts/*.tsserver.benchmark
            # TODO: publish blob, only on ResourceTrigger or explicit parameter true
            node internal/scripts/perf/bin/ts-perf benchmark tsserver \
              --tsserver $(Pipeline.Workspace)/BuiltTypeScript/main/tsserver.js \
              --load output/main.tsserver.benchmark
          fi
        displayName: Merge tsserver benchmarks
        condition: and(succeeded(), eq(variables['TSPERF_RUN_TSSERVER'], true))

      - bash: |
          if [[ $(REF) == refs/pull/* ]]; then
            node internal/scripts/perf/bin/ts-perf merge --output output/pr.startup.benchmark artifacts/pr_*.startup.benchmark
            node internal/scripts/perf/bin/ts-perf merge --output output/main.startup.benchmark artifacts/main_*.startup.benchmark

            node internal/scripts/perf/bin/ts-perf benchmark startup \
              --builtDir $(Pipeline.Workspace)/BuiltTypeScript/main \
              --baseline output/main.tsserver.benchmark \
              --load output/pr.tsserver.benchmark

            echo "<h2>Startup</h2>" >> comment.html
            node internal/scripts/perf/bin/ts-perf benchmark startup \
              --builtDir $(Pipeline.Workspace)/BuiltTypeScript/main \
              --baseline output/main.startup.benchmark \
              --load output/pr.startup.benchmark \
              --baselineName main \
              --benchmarkName pr \
              --format html-fragment \
              --quiet >> comment.html
          else
            node internal/scripts/perf/bin/ts-perf merge --output output/main.startup.benchmark artifacts/*.startup.benchmark
            node internal/scripts/perf/bin/ts-perf benchmark startup \
              --builtDir $(Pipeline.Workspace)/BuiltTypeScript/main \
              --load output/main.tsserver.benchmark
          fi
        displayName: Merge startup benchmarks
        condition: and(succeeded(), eq(variables['TSPERF_RUN_STARTUP'], true))

      - bash: |
          cat comment.html
        displayName: Publish PR comment
        condition: and(succeeded(), eq(variables['IS_PR'], true))

      # - checkout: self
      #   path: typescript-benchmarking
      #   fetchTags: false
      #   fetchDepth: 1
      #   clean: true

      # - bash: |
      #     cd $(Pipeline.Workspace)/typescript-benchmarking
      #     npm ci
      #     node ./scripts/postPerfResult.mjs comment.html
      #   displayName: Publish PR comment
      #   condition: and(succeeded(), eq(variables['IS_PR'], true))
      #   env:
      #     SOURCE_ISSUE: ...
      #     REQUESTING_USER: ...
      #     BUILD_BUILDID: ...
      #     STATUS_COMMENT: ...
      #     GH_TOKEN: ...

      - bash: |
          ls -lh output
          # TODO: actually upload
          # TODO: files need to be named correctly for the blob store
        displayName: Upload benchmarks to blob store
        condition: and(succeeded(), eq(variables['SHOULD_UPLOAD'], true))

      - publish: output
        artifact: Benchmarks
        displayName: Publish benchmarks

      # TODO: some sort of on-failure run which replies to PRs
